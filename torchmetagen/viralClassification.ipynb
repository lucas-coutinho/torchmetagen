{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0eec8eac285937831eaf55a324af314c8014d3f32e7d5b9fc0a7fa4a8002b4eb4",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "eec8eac285937831eaf55a324af314c8014d3f32e7d5b9fc0a7fa4a8002b4eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Loading data and traing a viral classifier on metagenomic sequences of mosquitoes\n",
    "\n",
    "## Import dependencies "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from datasets.utils import FastaHandler, DatasetSplit, InflateDataset\n",
    "from datasets import metagenomicdataset as meta\n",
    "from transforms import *\n",
    "from torchvision import transforms as tf\n",
    "import torch\n",
    "\n",
    "from models import DeepVirFinder, deepvirfinder\n",
    "from utils import *"
   ]
  },
  {
   "source": [
    "## Check for GPU devices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '~/Desktop/ViralClassificationAWS/datasets/Dataset_v1_2'\n",
    "\n",
    "viral = FastaHandler(path_to_file, 'viral.fasta',)\n",
    "nonviral= FastaHandler(path_to_file, 'nonviral.fasta',)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DatasetSplit({'train':0.7,'val':0.3 })\n",
    "\n",
    "viral_train, viral_test= splitter(viral)\n",
    "nonviral_train, nonviral_test= splitter(nonviral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inflate=InflateDataset(method='truncated', tol=0.5, chunk_size=500)\n",
    "\n",
    "viral_train_inflated = inflate(viral_train)\n",
    "viral_test_inflated = viral_test #inflate(viral_test)\n",
    "\n",
    "\n",
    "nonviral_train_inflated =  inflate(nonviral_train)\n",
    "nonviral_test_inflated = nonviral_test#inflate(nonviral_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train=tf.Compose([\n",
    "    ReverseComplement(),\n",
    "    ToOneHot(['G','T', 'C', 'A']),\n",
    "    ToTensor('one-hot')\n",
    "])\n",
    "\n",
    "transforms_test=tf.Compose([\n",
    "    ReverseComplement(),\n",
    "    ToOneHot(['G','T', 'C', 'A']),\n",
    "    ToTensor('one-hot')\n",
    "])\n",
    "\n",
    "\n",
    "dataset_train= meta.MetagenomicSequenceData(pd.DataFrame({\"data\":np.concatenate((nonviral_train_inflated, viral_train_inflated)),\n",
    "                                                          \"class\":np.concatenate((np.repeat(\"nonviral\",len(nonviral_train_inflated)),\n",
    "                                                                                  np.repeat(\"viral\",len(viral_train_inflated))))}),\n",
    "                                                     labels=['nonviral', 'viral'], transform=transforms_train)\n",
    "\n",
    "dataset_test= meta.MetagenomicSequenceData(pd.DataFrame({\"data\":np.concatenate((nonviral_test_inflated, viral_test_inflated)),\n",
    "                                                         \"class\":np.concatenate((np.repeat(\"nonviral\",len(nonviral_test_inflated)),\n",
    "                                                                                 np.repeat(\"viral\",len(viral_test_inflated))))}),\n",
    "                                                     labels=['nonviral', 'viral'], transform=transforms_test)\n",
    "\n",
    "dataset={'train': dataset_train, 'val': dataset_test}\n",
    "dataset_sizes = {'train':len(dataset_train), 'val':len(dataset_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = genDataLoader(dataset, {'train':250, 'val':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = deepvirfinder(pretrained=True, progress=True, M = 1000, K = 10, N = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 1.0567 Acc: 0.8383\n",
      "val Loss: 5.0865 Acc: 0.1800\n",
      "\n",
      "Training complete in 0m 16s\n",
      "Best val Acc: 0.180023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model_torch.parameters(), lr = 1e-4)\n",
    "criterion = torch.nn.BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,4)\n",
    "per_epoch, per_batch = train_model(model_torch.to(device), criterion, optimizer, \n",
    "                      scheduler, dataloaders, device, dataset_sizes, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-435f48706242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ViralClassificationAWS/utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device, report)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pd.DataFrame(evaluate(model_torch.to(device), dataloaders['val'], device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint_3.state_dict(), './first_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp aliagned_t18.fasta  aliagned_t18_teste.fasta\n",
    "grep '>' aliagned_t18_teste.fasta  > temp_headers\n",
    "while read p\n",
    "do \n",
    " h_query=`echo $p| cut -f1 -d \" \"| cut -f2 -d \">\"`\n",
    " h_subject=`grep $h_query -A5 diamondx_t12_f0.out| grep \">\"|tr \">\" \"|\"`\n",
    " sed -i \"s/$h_query/$h_query $h_subject/g\" aliagned_t18_teste.fasta\n",
    "done < temp_headers\n",
    "\n",
    "fasta_formatter -i aliagned_t18_teste.fasta  -o aliagned_t18_teste_linear.fasta\n",
    "cp aliagned_t18.fasta  aliagned_t18_teste.fasta\n",
    "grep '>' aliagned_t18_teste.fasta  > temp_headers\n",
    "while read p\n",
    "do \n",
    " h_query=`echo $p| cut -f1 -d \" \"| cut -f2 -d \">\"`\n",
    " h_subject=`grep $h_query -A5 diamondx_t12_f0.out| grep \">\"|tr \">\" \"|\"`\n",
    " sed -i \"s/$h_query/$h_query $h_subject/g\" aliagned_t18_teste.fasta\n",
    "done < temp_headers\n",
    "\n",
    "fasta_formatter -i aliagned_t18_teste.fasta  -o aliagned_t18_teste_linear.fasta\n",
    "\n",
    "grep -A1 -i \"virus\" aliagned_t18_teste_linear.fasta > viral_blastx_hits.fasta\n",
    "\n",
    "grep '>' alia\n",
    "grep -A1 -i \"virus\" aliagned_t18_teste_linear.fasta > viral_blastx_hits.fasta\n",
    "\n",
    "grep '>' alia"
   ]
  }
 ]
}